
ゲームや映画業界では強い需要があるものの、高品質なダンスモーションの自動合成は依然として困難な課題である。
本論文では、音楽駆動型ダンスモーション合成システム「ChoreoMaster」を紹介する。
ChoreoMasterは、ある音楽が与えられたとき、その音楽に合わせて、スタイル、リズム、構造などの観点から高品質のダンスモーションを自動生成することができる。
この目標を達成するために、我々は新しい振付指向の振付音楽埋め込みフレームワークを導入し、音楽とダンスフレーズ間のスタイルとリズムの関係に対して、
統一的な振付音楽埋め込み空間を構築することに成功した。
さらに、学習された振付音楽埋め込みをグラフベース動作合成フレームワークに組み込むことで、様々な振付ルールに従った高品質なダンスモーションを頑健かつ効率的に生成することができる。
さらに、ChoreoMasterは、プロダクションレディなシステムとして、ユーザが望む結果を得るために十分な制御性と包括性を有している。
また，実験により，ChoreoMaster が生成したダンスモーションがプロのアーティストに受け入れられていることを確認した． 

1 はじめに 
ダンスの歴史は古い。映画やゲームなどでは、ダンスの動きは一般的な要素であり、これらの業界では、高品質の3Dダンスアニメーション資産が豊富に要求されています。
しかし、ダンスアニメーションの制作は、非常にコスト高で非効率的であり、通常、アーティストが（通常は与えられた音楽に基づいて）ダンスを振り付け、
経験豊富なダンサーがダンスを披露し、モーションキャプチャチームがダンサーの動きを記録する必要がある。
この作業には、振付やダンスに関する技術やノウハウが必要であり、また、撮影したモーションをクリーニングして修復するという面倒な作業も必要である。
1分間のオリジナルダンスアニメーションは、簡単に数千ドル（US）もの費用がかかる。
そのため、この作業を自動的に行うことができるツールがあれば、大きなメリットがある。
音楽駆動型ダンスモーション合成の文脈で、ツールがプロダクションレディと見なされるためには、2つの基本的な特徴を持つ必要がある。
第一に、基本的な振付ルールを満たす高品質のダンスモーションを頑健かつ安定的に生成し、できれば各入力に対して複数の適切な選択肢を提供することである。
第二に、ユーザが合成過程を完全に制御でき、望ましい動作と望ましくない動作を指定でき、生成される動作の多様性と新規性を調整できること、などである。
残念ながら、ダンスモーション合成のための既存の研究手法は、どれも実用的なプロダクションツールへの転換に成功しておらず、
現在のところ、これらの要件を満たすソリューションは1つもない。

既存の動作を基に新しい動作を合成することは、コンピュータグラフィックスにおける動作合成の古典的なトピックである。
長年の研究の結果、グラフベースのフレームワークがこの問題に対する事実上の標準的な解決策となった。
このようなフレームワークでは、新しいモーションを合成するタスクは、典型的には、事前に構築されたモーショングラフの最適なパスを見つけることである[
    Arikan and Forsyth 2002; Kovar et al.］ 
このようなグラフを用いることで このようなグラフを用いた手法により、Kimら[2003]は、動作の拍子とリズムパターンを結びつける制約を付加して、
リズム動作を合成する最初の試みに成功した。
また、白鳥ら（2006）と金ら（2006）は、音楽駆動型ダンスモーション合成の問題を正式に提起し、
さらに、ダンスモーションセグメントと入力音楽クリップを関連付ける、より洗練された規則を開発した。
しかし，既存のグラフベースの手法の基本的な欠点は，ダンスの振り付けを過小評価し，単純化しすぎていることであり，
より大きなデータベースでテストすると，明らかに目に見えるアーティファクトが発生してしまう．
一方、ビートとリズムのような手作りの基本機能は、直感的には合理的に見えますが、実際には、スタイルの一貫性、構造の妥当性など、
音楽とダンスの間の深い本質的な文脈上のつながりをモデル化することができません。
一方、音楽はともかく、ダンスで広く使われている振付のルールについては、既存の手法では対応できず、
ダンス経験者からは「一見、ダンスの動きをつなぎ合わせたように見えるが、全体としてうまく構成されていない」という指摘がある。
人工知能技術の隆盛により、画像やテキストなど様々なデータの合成にディープジェネレイティブ技術が応用されている。
この文脈で、音楽駆動型ダンスモーション合成の問題も検討されている[Alemi et al. 2017; Tang et al. 2018]。
適切に設定された場合、これらの方法は、従来の手法よりも音楽とダンスの間のいくつかの深い関係を把握しているように見えるが、
それでもまだ実際の使用に必要な基準を満たすことはできない。
彼らの最も明白な欠点は制御性の低さで、ニューラルネットワークによって行われる合成は不可解なブラックボックスとして機能するため、
実用的な制作ツールとしては大きな欠点となります。
また、機械学習の観点から、ニューラルネットワークは低次元の潜在空間にデータを投影して特徴付けるため、その過程で高周波の動きの詳細はノイズとみなされ、意図的に無視される。
そのため、必然的に合成されるダンスモーションの品質が低下し、「鈍い」「ぼやけた」ものになってしまうのです。
さらに、既存の手法は一般的に、専門的な振付ルールに対する明示的な注意を欠いている。
その結果、学習されたモsデルの一般化可能性が制限される。Alemiら[2017]が指摘するように、
彼らのモデルは、トレーニングセット外の音楽を与えると、奇妙で美しくない動きを生成する可能性があります。
幸い、プロのアーティストとの複数のラウンドの反復と振付の理論の体系的な研究（例えば、［Mason 2012; Nor and Stepputat 2016］参照）の後、
我々は音楽駆動型ダンス動作合成の問題を促進するために利用できる、広く使われているいくつかの振付ルールを発見した。
具体的には 
- 音楽と身体の動きのスタイルは一貫しているべきで、同様のムードとトーンを伝える、
-同期したダンスと音楽の各セグメントは同じリズムパターンを示すべきで、ダンスフレーズのリズムパターンは非常に規則的に現れる、
-ダンスの構成は対応する音楽の構造と協調すべき、例えば、繰り返しの音楽フレーズ（詩やコーラス）は一般的に繰り返しの動きに関連し、
フレーズの同一メーターはしばしば対称の動きに対応します。

このルールに従うことで，合成されたダンスはプロのアーティストが期待するような適切な美的水準に到達することができる。
このルールに基づき、我々は振付指向の音楽駆動型ダンスモーション合成システムChoreoMasterを開発した（図1参照）。
図2に示すように、ペアとなる音楽とダンスモーションのシーケンスを含む注釈付きデータベースから、
まず、振付指向のコレオミュージック埋め込みモジュール（セクション3参照）を用いて、音楽とダンスのつながりを捕捉する。
具体的には、音楽とダンスのフレーズを、類似したスタイルのフレーズが密接にクラスタリングされた統一空間にマッピングすることでコレオミュージカルスタイル埋め込みを、
音楽とダンスの動作の各メーターに対してリズムパターンを特定することでコレオミュージカルリズム埋め込みを見つける。
さらに、学習された振付音楽埋め込みをグラフベース動作合成フレームワーク（セクション4参照）に組み込むことで、
様々な振付ルールに従った高品質なダンス動作を頑健かつ効率的に生成し、同時にユーザに対して高い制御性を提供することができる。
実験により、ChoreoMaster は、プロのアーティストが認める多様で高品質なダンスモーションを頑健かつ効率的に生成できることが実証された。
ChoreoMasterは、Netease Gamesのいくつかのプロジェクトで、何時間ものダンスアセットを生成することに成功しており、
我々の知る限り、この目的のための業界初の制作可能なツールである。
本論文の貢献は、以下の通りです。
- 本論文では、振付理論から3つのルールを導入し、音楽駆動型ダンスモーション合成を容易にする。 
- 導入したルールを組み込んだクロスドメインエンベッディングフレームワークを開発し、
限られた高品質の音楽／モーションデータから複雑な振付音楽の関係を正確かつ効果的に特徴付け、
定性的な振付知識を計算可能なメトリックに変換することに成功した。
- このシステムは、高品質なダンスモーションを高い制御性で頑健に生成できる。 
- 深い特徴、グラフベースのフレームワーク、従来の最適化手法を効果的に組み合わせることで、
意味的に正しく、頑健で制御性の高い、オーディオベースのアニメーション合成ツールを提供できることを実証する。

2 関連する仕事 
このセクションでは、関連する分野の先行研究について述べる。 
2.1 グラフベース動作合成 
動作合成は、コンピュータグラフィックスにおいて長い間重要なトピックであり、
その主な目的は、既存の動作データベースから新しい3D骨格動作を合成することである。
Lamouretら[1996]はこのアイデアを提起し、データベースから既存のモーションセグメントをカットアンドペーストで組み合わせて
新しいモーションを作成する最初のプロトタイプシステムを発表した。
Arikanら[2002]、Kovarら[2002]、Leeら[2002]は、グラフベースのモーション合成の概念を正式に導入し、
問題をあらかじめ構築されたモーショングラフのパスを見つけることと見なした。
また、Kim ら[2003]はこのフレームワークを拡張し、動きの拍子やリズムパターンを含む制約を導入することで、
リズミカルな動きに対応するようにした。また、白鳥ら[2006]とKimら[2006]は、
モーショングラフの経路探索において、より高度な音楽と踊りのマッチング制約を開発した。
Ofliら[2011]とManfrèら[2016]は、隠れマルコフモデル（HMM）を用いてこの問題を定式化し、
動的計画法やビーム探索アルゴリズムを用いて効率的に解くことができるようにした。
Bermanら[2015]は、ダンサーや振付師の創造的プロセスを支援するために、
モーショングラフを使用して新しい種類のダンスの動きを生成する可能性を議論した。
時間の経過とともに、グラフベースのフレームワークは、その多くの利点のために、
モーション合成問題に対する事実上の標準的なソリューションとなった。
例えば，Yang ら [2020] は最近グラフベースのフレームワークを利用して，
社会的な会話のためのボディモーションを合成することに成功した．
モーショングラフが適切に構築されていれば、合成されたモーションの隣接するセグメント間の遷移は
滑らかであることが保証される。
しかし、プロのアーティストの視点から見ると、ダンスは単にダンス要素のシーケンスを滑らかにつなぎ合わせただけのものではありません。
技術的には，我々のシステムは，モーショングラフの構築からグラフベースの最適化まで，
従来のグラフベースのモーション合成フレームワークを振付指向に拡張したものとみなすことができ，
そこでは振付のルールが全体的に尊重されている．
2.2 Music-to-Dance Cross-Modal Mapping 
音楽とダンスのつながりを適切に定式化することは、音楽駆動型ダンスモーション合成にとって極めて重要である。
ダンス動作と音楽をよりよく関連付けるために、さまざまな試みがなされてきました。
初期のアプローチ[Kim et al. 2006; Lee et al. 2013; Ofli et al. 2008; Shiratori and Ikeuchi 2008; Shiratori et al. 2006]では、
音楽信号（例：オンセット、クロマ、MFCC）とダンス動作（例：動作速度、関節軌道）で検出した特徴に基づいて
類似性検索を行うのが一般的である。
画像特徴もダンス動画から視覚的なビートを抽出するために検討されている[Davis and Agrawala 2018]。
学習ベースの手法も検討されている。
例えば、Fanら[2011]はブーストベースの学習アルゴリズムを用いて音楽をモーションマッピングのスコアに回帰させ、
Fukayamaら[2015]は確率モデルを採用してダンスモーションを与えられた音楽に割り当てる尤度を測定している。
これらの方法は、音楽とダンスの間のいくつかの表面的な接続を利用することができますが、
一般的に深い本質的な振付音楽の関係をモデル化することができません。
さらに、ペアリングされたデータを必要とするため、ペアリングされていない音楽とモーションのデータを利用することができません。
振付は経験的な学問であり、前述のように、従うべきいくつかの否定しがたい一般的なルールがある。
すなわち、クロスモーダルなスタイル埋め込み処理では、音楽とダンスのセグメントを、
類似したムードとトーンを伝えるセグメントが密接にクラスタ化された統一潜在空間にマッピングすることを学習し、
次に、コレオミュージカルリズム埋め込み処理では、音楽とダンスの動作の各メーターに対して可能なリズム記号を割り当てることを学習する。
なお、本手法では、音楽とダンスが対になっていないシーケンスも利用することができる。
本アプローチの定量的・定性的評価により、本フレームワークが特徴付ける振付音楽関係は、
合成されたダンスモーションの健全性と自然性を大きく向上させることができることが示された。

2.3 ディープジェネレーティブダンスモーション合成 
最近，ディープジェネレーティブ手法もダンスモーション合成の問題に適用されている。
モーションデータの次元に基づいて，既存の方法は2Dと3Dのソリューションに分けることができる。
Leeら[2019]は、VAE（variational autoencoder）でダンスユニットをモデル化し、GAN（generative adversarial network）を用いてダンスシーケンスを再帰的に生成する、
最初の2D music-to-dance generation frameworkを発表しました。また、
人間の骨格は自然にグラフを形成するため、Renら[2020]とFerreiraら[2020]はGCN（グラフ畳み込みネットワーク）を用いて、生成された2Dダンスモーションの自然さを向上させている。
これらの進歩にもかかわらず、2Dダンスモーション合成は、我々のシステムとは異なる目標を持っています。
ダンスアニメーションを生成するのではなく、生成された2Dポーズシーケンスは、ダンスビデオ生成のための中間ガイダンスとして機能する。
3次元が存在しないため、2次元のフレームワークを3次元のシナリオに適用することは非常に困難である。
ニューラルネットワークで3Dの人間の動きを合成するというアイデアは、Grzeszczukら[1998]によって最初に提案されました。
その後、Leeら[2006]は、人間の首の動きを合成するためにニューラルネットワークを採用した。
深層学習技術の台頭以来、様々な時系列データ生成フレームワークが音楽駆動型3Dダンスモーション合成目的に適応され、
例えば、時間畳み込みオートエンコーダ［Holdenら2016］、FCRBM（factored conditional restricted Boltzmann machine）［Alemiら2017］、
LSTMautoencoder（LSTMautoencoder）［Alemiら］。2017]、LSTMautoencoder [Tang et al. 2018]、
CSGN (convolutional sequence generation network) [Yan et al. 2019]、
GAN [Sun et al. 2020]、Bi-LSTM combined with temporal convolution [Zhuang et al. 2020], transformers [Li et al. 2021] 等がある。
これらの方法の背後にある重要な考え方は、音楽を低次元の潜在空間に符号化された動きに変換し、
潜在空間からの復号化によって対応するダンスモーションを回復することである。
しかし、前述のように、制御性が悪く、パフォーマンスが不安定であるため、実際の制作現場には不向きである。
このような問題を軽減するために，最近のいくつかのアプローチ[Duan et al.2020; Ye et al.2020]は，
骨格となるダンスモーションの代わりに，あらかじめ定義されたダンスアクションユニットの集合から構成されるシーケンスに音楽を翻訳している．
しかし，Duan [2020]が指摘するように，このような手法ではダンスフレーズ間のスムーズな遷移さえも常に保証されるとは限らない．
しかし，グラフベースのフレームワークは，より強力で柔軟なアクションユニットの配置と，より高い制御性・解釈性を提供することは明らかである．

3 CHOREOGRAPHIC-ORIENTED CHOREOMUSICAL EMBEDDING 
3.1 背景 
音楽とダンスは太古の昔から表裏一体であり，その関係は人類の文明とともに発展してきた．
このような音楽とダンスの関係を研究する学問は，ダンス振付の理論と実践をまとめたコレオミュージック学［Mason 2012］
と呼ばれる学問分野を形成している．明らかに，振付の規則を尊重したダンスモーションを生成することは，私たちのシステムにとって不可欠です．
しかし，他のあらゆる芸術形式と同様に，ダンスの美学と振付音楽のスタイルとリズムの関係の評価は，かなり複雑な問題であり，
形式化することが困難である．具体的には、スタイルとリズムは、音楽とダンスの両方において、比較的独立していながら、
密接に関連する2つの要素である。一方では、同じリズムパターンに従う音楽とダンスが、全く異なる聴覚的・視覚的スタイルを示すことがあり、またその逆も然りである。
一方、リズムパターンの分布は、音楽とダンスのスタイルに強く関連している。
例えば、癒しの音楽は柔らかいリズムを持ち、ロックミュージックは強いビートを持つ傾向がある。
このような音楽とダンスの複雑なスタイルとリズムの関係を適切に表現することは、音楽駆動型ダンスモーションの合成において非常に重要である。
さらに、そのような振付音楽的な関係を分離して提示することが、システムの解釈可能性と制御可能性を著しく向上させる。
このため、図3に示すような振付指向の振付音楽埋め込みフレームワークを用いて、次に説明する。

3.2 振り付け音楽のスタイルの埋め込み 
スタイルの一貫性は、ダンス作曲の基本要件である。
勢いのある動きと落ち着いた音楽を組み合わせると、独特のダンスになる。
そこで、音楽とダンスをスタイルごとに分類し、入力された音楽と同じカテゴリーに
属するダンスを合成することで、スタイルの一貫性を保つ方法がある。
しかし、このような解決策では、実は満足のいく結果を得るには不十分であり、また実践するのも難しい。
まず、異なる音楽やダンスのスタイルの境界は、必ずしも明確ではない。音楽やダンスにスタイルのラベルを付けるには、
多大な専門知識が必要である。第二に、音楽は聴覚を、ダンスは視覚を呼び起こすものであるため、分類の基準が異なる。
例えば、音楽もダンスもジャンルによって分類することができますが、ほとんどの音楽やダンスのジャンルは、その相手方に相当するタグを持っていません。
第三に、音楽やダンスの主なスタイルはそれぞれ多数のサブスタイルを含んでおり（例えば、ヒップホップはさらにポップ、ロック、ブレイキング、アーバンなどに分類される）、
音楽やダンスデータを明示的に分類することによってスタイルの一貫性を実現することはさらに困難である。
この問題に対処するため、我々は、音楽とダンススタイルのつながりを暗黙的にモデル化するchoreomusical embedding networkを採用する。
本論文のキーポイントは、音楽とダンスのセグメントを、類似した雰囲気や音色を伝えるセグメントが密接にクラスタリングされた
統一的な埋め込み空間にマッピングすることである。
具体的には、まずペアリングされていない音楽とダンスのデータを用いて2つの分類ネットワークを独立に学習し、
次にペアリングされたデータを用いて2つの特徴空間を統一的な埋め込み空間に変換する。
このとき、音楽とダンスの項目は分類可能なまま、ペアリングされた音楽とダンスの項目はできるだけ近い状態で分類される。
そのアーキテクチャを図3（左）に示す。音楽符号化枝𝐸ǔのバックボーンとして、主に[Choi et al. 2017]の最先端音楽タグ付けネットワークを採用した。
これは 4 つの畳み込みブロック層と 2 つの GRU 層で構成される。𝐸ǔ と対称的に、畳み込みブロックをグラフ畳み込みブロックに置き換える以外は、
ダンス符号化ブランチ 𝐸𝐷 を構築する。𝐸𝑀と𝐸𝐷の一般的な目的は、音楽とダンスシーケンスを二つの32次元埋め込みベクトル、すなわち、それぞれ𝑀と𝐷に圧縮することである。
本実装では，音楽データは16kHzにダウンサンプリングし，対数振幅メルスペクトログラム（96メルビン，160ホップサイズで計算）で表現し，
ダンス動作データはグローバル関節位置（指やつま先を含まない18個の主要な身体関節を使用）で表現している。
音楽／ダンスフレーズはスタイルを表現する最小単位と考え、入力長を一般的な音楽／ダンスフレーズの長さである8秒
（すなわち、30fpsダンスモーションの240キーフレーム）に設定した。したがって、𝐸𝑀の入力形状は[1, 96, 800]、𝐸𝐷は[3, 18, 240]である。
ペアリングされていない膨大な量の音楽とモーションのデータを活用するため、2段階の学習手順を採用した。
第1段階では、ラベル付けされた未対応の音楽・ダンスデータを全て用いて、音楽ブランチとダンスブランチを独立して学習させる。
学習された埋め込み空間における潜在的なサブスタイルをよりよく反映するために、分類ネットワークの特徴空間におけるデータをよりよくクラスタリングすることを促す、
Xieら[2016]が提案した教師なし深層埋め込みクラスタリング（DEC）戦略も取り入れる。
音楽とダンスの埋め込みのための学習損失は 
Ll_145A↩ = 𝜆1𝐿 + 𝜆2 𝐿dec 
Ll_1451↩ = 𝜆1𝐿𝑑 + 𝐿dec (1) where 𝐿, 𝑑 is the classification losses (i.e......), クロスエントロピー損失）、
𝐿は[Xie et al. 2016]の式（2）で定義されるKL発散損失、ᜆとᜆは釣り合い重みである。
次に、第2フェーズでは、同期した音楽とモーションのペアを用いて2つのブランチを共同で学習し、
ここで学習損失は次のように定義される。
Lstyle = 𝜆3ᵃ𝑑 + 𝜆4ᵃ𝑚 + Ǖ (2) ここでᵃ𝑑は分類損失、𝐿𝐷とᵄǗは間のMSE損失、および↪Lu_1D6, ... ... は分類損失である。
Ű5は重みである。これらの2段階の学習により、任意の音楽とダンスセグメントを統一的なコレオミュージカル埋め込み空間にマッピングすることができる。
ここで、音楽とダンスのスタイルの一貫性は、対応する埋め込みベクトル間のユークリッド距離で測定することができる。

3.3 振動音楽のリズムの埋め込み 
よく構成されたダンスでは、身体の動きは音楽のリズムと協調していなければならない。
音楽理論では、リズムという言葉はしばしば音楽のメーターの用語で表現される。
拍子とは音楽の基本的な時間的単位であり、拍子の組織的パターンを意味する。
したがって、ダンスの動作にも拍子と拍子を用いることができる。
一般に、音楽の拍は音楽の音のパルスに対応し、ダンスの拍は体の動きの休止や急旋回に対応する。
拍子は、2／4、3／4、4／4などの拍子記号で表され、上の数字が1小節の拍数、下の数字が1拍のテンポ時間である。
例えば、4／4拍子の場合、1小節に4分音符の拍が4つ含まれる。リズムはスタイルとは異なり、楽譜で明確に表現することができる。
しかし、ダンスの動きを音楽のリズムに合わせることは、まだ難しい。
音楽には複数の楽器やボーカルがあり、ダンスでは多くの関節が同時に動く。
そのため、音楽のトラックや体の関節はそれぞれ独自のビートパターンを持っており、どのビートパターンに合わせるべきかは難しい課題である。
例えば、音楽に合わせてダンスを作る場合、振付師はドラムのビート、ピアノのメロディー、人間のボーカルなど、それぞれ異なる部分を追いかけることを好むかもしれない。
そこで、音楽とダンスのリズムの関係を理解するために、プロのアーティストに手作業でダンスの拍子パターンを指定してもらい、データベース化した。
これにより、音楽のビートパターンをダンスと同期して取得することができた。その結果、各メーターのビートパターンは、数学的に2値のベクトルとして表現できることがわかった。
このベクトルは、統一的な振付音楽のリズム埋め込みの自然な包括形である「リズムシグネチャ」と呼ぶ。
本データセットに含まれる全てのダンスモーションは4拍子で構成されているため、本システムでは8ビットのリズム記号を提案している（図4参照）。
偶数ビットは正拍（1：あり、0：なし）を表し、奇数ビットは半拍（1：あり、0：なし）を表し、二つの正拍の間のリズム点（通常はタイ、休符、点、
または単に隣接する拍が複数の小さな拍で構成されているため）を説明する。
リズム記号に連続するゼロは、音楽とダンスの動作におけるレガート、または滑らかな周期を示します。
2つのリズム記号の距離は、ハミング距離（2つのビットパターンが異なるビット位置の数）を使って定義することができる。
ここでは、正拍を重視するため、正拍を1.0、半拍を0.5とし、ビットごとに重みを変えてハミング距離を計算する。
理論的には、2 8 = 256種類のリズム記号が存在することになる。
しかし、ラベル付けされたデータを統計的に分析した結果、一般的なリズム記号の数は13種類程度に過ぎないことが分かった。
また、ダンスの種類によって、リズム記号の分布が大きく異なることも興味深い発見であった。
例えば、中国の伝統舞踊ではレガートが多く、ヒップホップでは半拍が多い。
このように、スタイルとリズムは相互に影響し合っているのです。
以上の考え方に基づき、我々は、音楽やダンスのためのコレオミュージカルリズムの埋め込みを効率的に獲得するために、
リズム署名分類ネットワークを設計した。

このネットワークのアーキテクチャを図3（右）に示すが、これは3つのブロックから構成されている。
音楽𝐸𝑀とダンス𝐸𝑅のための二つの独立した特徴抽出ブロックがあり、それぞれ二つの畳み込み層と一つの密な層で構成されている。
最後に、リズム記号分類のための共有ブロック𝐸𝑆があり、3つの密な層で構成されている。
対応する音楽セグメントᵄとダンスセグメントǔのスタイル埋め込みベクトルは、スタイルとリズムの統計的相関が既に観察されているので、
それぞれ𝐸_1D440ǔと𝐷で抽出した特徴ベクトルに連結される。
スタイルとリズムの埋め込みブランチにはいくつかの違いがあることは注目される。
第一に、リズム埋め込みの目的は、潜在的なベクトルではなく、明示的なリズム署名を決定することである。
リズム署名は明確な定義を持つため、我々のシステムにより解釈可能性と制御可能性を与えるからである。
第二に、リズム記号は小節単位で定義されるため、リズム埋め込みに使用するテンポ単位はフレーズではなく1小節（すなわち、我々のシステムでは2秒）に設定される。
ここで、ある小節のスタイル埋め込みは、その小節が属するフレーズのスタイル埋め込みを指す。
第三に、拍は音楽のパルス変化や関節動作の速度・方向変化に反映されるため、低レベルの原信号からネットワークを学習させる必要はない。
その代わりに、抽出されたある種の特徴をネットワークに与える。具体的には、音楽の場合はスペクトルオンセット強度曲線[Böck and Widmer 2013]とRMSエネルギー曲線
（次元：[2, 200]）、ダンスの場合は運動曲線、二つの手の軌道の曲率曲線、二つの足の接触曲線（次元：[5, 60]）が挙げられる。
運動学的曲線は，白鳥ら[2006]が提案した重み付き角速度関数を用いて計算されている．
手の軌跡曲率曲線には両手首関節の軌跡の曲率が、足の接触曲線には両足と床との接触情報が記録されている。
このネットワークのすべてのブロックは、ラベル付けされたペア音楽とダンスデータを用いて、以下の損失関数で共同学習される。
Lrhythm = Ű6𝐿ᑑŰ7ᑟ (3) ここで、ᑟとᑚはそれぞれダンスと音楽の分類損失、Űとᜆは重みである。
大きな予測誤差と従来のクロスエントロピー損失を考慮し、𝐿ᵅとᵅを計算する際に、予測されたリズム署名とグランドトゥルースのリズム署名間の重み付きハミング距離を追加する。

4 CHOREOGRAPHY-ORIENTED DANCE SYNTHESIS 
前述のように、生産可能なツールにおいては、包括的な制御性が非常に重要である。
そこで、グラフベースのモーション合成フレームワークを採用する。典型的なグラフベースの動作合成フレームワークは、
動作グラフの構築とグラフベースの最適化という2つの重要なステップを含んでいる。
このセクションでは、学習された振付音楽的埋め込みと他の振付ルールが、どのように我々のグラフベースのモーション合成フレームワークに組み込まれるかを説明する。

4.1 モーショングラフの構築 
モーショングラフは有向グラフであり，各ノードはデータベース内のモーションセグメントを表し，各エッジは隣接する2つのノード間の遷移コストを表す。
従来のグラフベースのダンス動作合成システムでは、ダンス動作を動作ビートに分割し、関節位置間の距離と動作速度に基づいて遷移コストを計算するのが一般的であった。
しかし、この方法では、1つのダンスメータ内の動作の相関が無視される、2つの動作間のスタイルの互換性が考慮されないという問題がある（図5参照）。
本システムでは、これらの問題を解決するために、振付ルールを導入した。
本システムでは、ダンスモーションの拍子の代わりに、モーショングラフの各ノードがダンスモーションメータに対応する。
また、各グラフのノードには、学習したスタイル埋め込みベクトルとラベル付けされたリズム記号が付加されている。
既存のデータをより有効に利用し、より多様な合成結果を促すために、我々のデータベース内のダンスモーションメーターは3つの方法で補強されている（図6参照）。
- ミラーリング：ダンスの動きを左右にミラーリングする。 
- ブレンディング：2つの異なるメーターの上半身と下半身の動きをブレンドして新しいモーションメーターを作る。 
- シャッフル：2つの異なるメーターのモーションビートをシャッフルして2つの新しいモーションメーターを作る。
例えば、「1234」と「abcd」がスムーズにステッチできる場合は「12cd」と「ab34」を作ることができる。
ミラーリング操作はデータベース内のすべてのモーション メーターに適用されますが、
ブレンドと再シャッフルは非常に控えめに実行されます（つまり、同じリズム署名と非常に近いスタイル エンコーディングを持つメーター間のみ）。
ブレンドと再シャッフルによって増強されたすべてのモーションは、手動でチェックされました。
モーショングラフの新しいノードは、すべての有効な拡張のために作成されます。
また、モーショングラフではスタイルの互換性が尊重されている。
具体的には、2つのノードǔとᵅの間のエッジ遷移コストは次のように定義される。𝑇 (ǔ, ᵅ) = ǖ8𝑇 + ǖ9𝑧 (4) ここで𝑁は通常の動作移行コストで、位置距離（m）の合計として算出されます。
回転(ラジアン)と速度(メートル/秒)の距離の合計として計算され、ᑧは2つのスタイル埋め込みベクトル間のユークリッド距離である。ᜈとᜆは重みである。
隣接するノード間の遷移コストが閾値ǿ𝑇以下の場合、グラフ内にエッジが生成される。ǿᵄが大きいとグラフ内のエッジが多くなり、
結果の多様性が増すが、悪い遷移エッジもグラフに含まれる可能性があり、アーティファクトの原因となる。

4.2 グラフベースの最適化 
グラフベースのフレームワークでは，合成された各モーションはモーショングラフのパスに対応する。
したがって、本システムでは、入力音楽に対するダンスモーションの合成は、グラフ内の様々な振付ルールを満たす最適なパスを見つけることと見なすことができる（図7参照）。
本システムでは、まず、入力された楽曲を[Gainza 2009]で提案された小節自動検出アルゴリズムを用いて小節単位に分割する。
次に、Serra et al [2012; 2014]が提案する音楽分割と類似性ラベリング手法を用いて、音楽的に意味のあるフレーズを全て取得する。
フレーズ内の類似した小節はさらに検出され（小さな閾値内のスペクトログラム差を有する）、IDが付与される。
全体として、音楽中の各小節𝑀𝑖に構造タグ（図7の𝐴 1 1 2 , 𝐴 1 1 2）、𝐴はフレーズID、添字と上付き文字はそれぞれフレーズのインデックスとメーターのIDを表している。
次に、音楽列𝑀 = {𝑀 ｜𝑖 = 1, ... ...の各メーター𝑀に対して、そのスタイルを求める。
𝑛}で、そのスタイル埋め込み𝑍と上位ᵃ可能なリズム署名{𝑅 1 𝑀𝑖 , ... ...}を得る。
, 𝑅 𝑀𝑖 }となる。本システムの目標は、モーショングラフのダンスモーションノードǔ𝑖を各音階𝑀𝑖に割り当てて、以下のコストを最小化することである。
ǔ = ǖ 10 𝑛 𝑖=1 𝐶𝑑 (𝑖,𝑖 + 1) + 𝜆 11 Õ𝑛-1 𝑖=1 𝐶ᵆ (𝑖,𝑖 + 1) + ↪Ll_1D701 Õ𝑛 𝑖<l_1D457↩ ↪Lu_1D436ǔ (𝑖, ↪Ll_1D457) (5) where 𝐶 , 
𝐶 𝑡はそれぞれデータ項、遷移項、構造制約項、𝜆、ᜆは重み、𝜁は大きなペナルティ係数である。
データ項 𝐶 (𝑖) は、ミュージックメーター𝑀𝑖とダンスモーションメーター𝐷𝑖の間のスタイルとリズムの一致コストを占め、
次のように定義される。𝐶 = 𝑑 (𝑖) = ᵃ𝑧 (ᵄ𝐷) + ᵃ min 𝑘 (ᵃ 𝑘 𝑀𝑖 , 𝑅𝐷𝑖 ) (6) 
ここで、ᵃは音楽／ダンスメーター間のスタイル埋め込み距離、リズム署名距離、ᵃᜆとᜆは二つの重みである。
遷移項。↪Lu_1D436 (𝑖) は合成されたモーションの隣接するモーションセグメント間のスムーズな遷移を保証し、
グラフエッジに格納された遷移コストに等しい： 𝐶 (𝑖,𝑖 + 1) = 𝐷 𝑁 (𝐷𝑖 + 1)。構造項。
𝐶ǔは、音楽とダンス間の構造的な整合性を扱う。振付家はしばしば、音楽の反復構造を反映させるために動作の反復を用いる。
例えば、繰り返される音楽のフレーズ（詩とコーラスなど）は、繰り返しの動きに対応することが多く、フレーズ内の同じ小節は、対称的な動きに対応することが多い。
このような振付規則から派生して、我々は2つの構造的制約を含む。
繰り返し制約では、𝐷𝑖と𝑀𝑖と𝑀𝑖が異なるフレーズに属し、フレーズID及びインデックスIDが同じであれば、𝐷と𝑖は同じ動作であるべきであるとする。
また、ミラー制約の場合、𝐷𝑖と↪L_1D437↩ᑗは、𝑀𝑖とᑗが同じフレーズに属し、そのメーターIDが同じなら、2つのミラーされた動作でなければなりません。
𝐷とᑗの各ペアについて、いずれかの制約に違反した場合、𝐶 (𝑖, ᑗ) は 1 に設定される。𝐶, ᑗ）= 0, 𝐷𝑖と𝐷ᑗが制約を満たす場合、それ以外は1である。

その他の実用的な要求も制約に変えることができ、このフレームワークに容易に取り入れることができる。
最適なダンス動作の順序は、動的計画法 [Forney 1973] を用いて効率的に合成することができる。
これを複数回実行し、使用する動作をスキップすることで、同じ入力音楽に対して異なるダンスモーションを容易に生成することができる。
5 評価 本手法の評価を行う。まず，本手法のセットアップを示し，次いで，いくつかの最先端手法との定量的・定性的な比較を行う．
また，本手法の性能と効率について総合的に分析し，最後に，ChoreoMaster の制御性が期待できることを示す．
表 1. 音楽と踊りのスタイル分布。
各楽曲は2次元のスタイル属性でラベル付けされている。
データベース モーションリソースは、アニメコミュニティから収集した高品質なダンスモーキャップリソースとMikuMikuDance（MMD）リソースで構成されています。
合計19.91時間のダンスモーションがあり、そのうち9.91時間にはペアとなる音楽がある。
4.1節で紹介したモーション補強技術を利用することで、データベース内のダンスモーションを2.56倍に拡張することができた。
さらに、1,954曲、総時間102.5時間の大規模な音楽データセットも収集した。ダンスと音楽は半自動的に小節とフレーズにセグメント化されている。
すべての音楽とダンスは、表1に示すように、2次元のスタイルでラベル付けされている。
表1のラベルは、多くのタグ候補のコレクションから得られたものである。
これらのラベルを用いた様々な人のアノテーションは比較的一貫しており、より説得力があるため、私たちはこれらを保持することにした。
ChoreoMaster は、特定のタグ付けシステムの必要性や充足性に依存しない。
なぜなら、これらのタグは、合成プロセスにおいてハードマッチング制約として使用されないからである。
また、ダンスが同期している音楽のリズム記号を得ることができる。周波数が 0.5％未満のリズム記号はノイズとみなし、
別の一般的な記号に分類し直した。表2に示すように、合計13のリズム記号を保持した。例えば，00000001は伝統的なダンスでは44.8%の頻度で出現するが，
ヒップホップダンスでは11.9%しか出現しないなど，特定のダンススタイルでより頻繁に出現するリズム記号がある。
また，音楽とダンスのペアをランダムにトレーニングセット（80％），検証セット（10％），テストセット（10％）の3つに分割し，
トレーニングセットと検証セットを用いて，音楽とダンスがどのような関係にあるかを検証した．

システム環境。
ハイパーパラメータを設定する。𝜆1, . . . ᜆ13 = 0.7, 0.3, 0.5, 5, 0.4, 0.6, 1, 1.5, 1, 2, 1, 1.5, 
ǖ = 20,ᵃ = 3, Ǘ = 1000とする。𝜆1, . . . Ű7は埋め込みフレームワークに関与しており、
グリッドサーチを用いて定性的に最適化された。ᜆ8, ..., ᜆ13, ᜇ は合成プロセスを制御し、
滑らかさ、新規性、スタイルとリズムの一貫性の重要性の希望に応じてユーザーが調整することができる。
Ű8、...、ᜆ13およびŰのデフォルト値は、プロのアーティストに相談して決定された。
実験によると、ChoreoMaster は広い範囲のパラメータでうまく機能することがわかった。
すべてのネットワークは P40 GPU サーバー上の PyTorch を使って学習された。
ダンス合成システムは、3.20GHz i7-8700 CPU、16GB RAM、GTX 1080Ti GPUを搭載したデスクトップでテストされました。
𝐸𝑀と𝐸𝐷はそれぞれAdamとSGD最適化器を用いて学習し、DECのクラスタ数は音楽で12、ダンスで20に設定した。
𝐸ǔ, ǔ, 𝐸ǔはSGDオプティマイザーを用いて学習した。バッチサイズ64、学習率0.001で、500エポックの学習を行った。
また，埋め込みネットワークはスタイル埋め込みに13時間，リズム埋め込みに1時間，合計14時間かけて学習させた。
5.2 比較 このセクションでは、本システムの進歩を示すために、いくつかの代替ダンス生成方法と本方法を比較する。
まず，これらの手法の簡単な紹介を行い，次に定量的な比較を行い，さらに包括的なユーザ調査による定性的な評価を行う．
詳細は補足資料を参照されたい．我々は，2つの伝統的なダンス合成手法と，生成モデルに基づく3つの最新の3Dダンス合成手法を比較対象として選びました．
Leeら[2013]は，入力された音楽クリップと既存の音楽クリップの類似性を評価することで候補となるモーションを検索する伝統的なダンス合成手法を提案した．
深山ら[2015]は，入力音楽に対してダンスシーケンスを最適化する確率的なモデルを構築した．Yanら[2019]は、
グラフ畳み込みを利用して潜在変数からスケルトン列を構築するCSGNを提案し、3Dダンスモーションの生成に利用した。
Sunら[2020]は、3Dダンス生成のためのGANベースのクロスモーダル関連付けフレームワークであるDeepDance法を提案した。
Liら[2021]は、音楽条件付き3Dダンス生成のためのクロスモーダル変換器ベースのモデルを利用した。
現在、[Fukayama and Goto 2015] と [Li et al. 2021] のコードやデータにアクセスできないため、同じ音楽を使ってダンスを合成し、
彼らの公開したデモ動画で示された結果と比較しました（補足動画で確認できます）。
さらに、スタイル埋め込み、リズム埋め込み、構造的制約を順番に取り除いて結果を生成するアブレーション研究も実施しました。
これらの手法は音楽とダンスのペアしか扱えないため、公平に比較するために、全ての手法に9.0時間の音楽とダンスのペアを与えて学習させ、
残りの0.91時間をテスト用に残しました。また，リズムアノテーションは，データセグメンテーション（Yanら[2019]，Sunら[2020]）やビート検出（Leeら[2013]）にも使用された。
テストデータから20クリップ、30-90秒の音楽クリップについて、自動生成されたダンス結果について比較を行った。
図8は比較結果の一例であり、その他の比較結果は補足動画に掲載している。

定量的な評価 
これらの手法を定量的に比較するために，表 3 に示すようないくつかの評価指標を採用した．
これらの評価指標は 1. FID スコア。Fréchet inception distance (FID) [Heusel et al. 2017] を用いて，
生成されたダンスの分布が実際のダンスの分布にどれだけ近いかを測定した。
Lee et al.2019]に従い、我々は特徴抽出器として我々のダンスデータセットでモーションオートエンコーダを
訓練した。表3のFIDは、我々のフレームワークがより多くの振付分野に対応しているため、
我々の生成したダンスが他の方法よりも実際のダンスに近いことを示している。
2. 2. ビート精度 
これは、モーションのビートが音楽のビートとどれだけ正確に一致しているかを測定するもので、
音楽の全ビートに対する一致したビートの比率で表される。
我々は、ラベル付けされた音楽リズム署名をグランドトゥルースとし、
[Shiratori and Ikeuchi 2008]で提案された運動リズム検出法を用いて、
運動ビートを検出した。表3に示すように、Choreomusical rhythm embeddingを
学習させたChoreoMasterは、全ての手法の中で最も高いビート精度を達成していることが分かる。
また、リズム記号を用いない場合の結果はかなり低く、リズム記号の有効性を示している。
3. 多様性（Diversity）。Lee et al. 2019]に従い、
異なる音楽入力に対する生成ダンス間の平均特徴距離を評価した。
FID の測定で使用したのと同じ特徴抽出器を再び使用した。
表 3 に示すように、我々の方法は最高の多様性スコアを達成した。
さらに，構造的制約があるため，動作の繰り返しが課されるため，
構造的制約がない場合の結果の方が若干高くなっている．
ユーザスタディ。ダンスの品質評価は非常に主観的であるため，
我々の手法を定性的に評価するために，ユーザスタディも行った．
30 個のテスト用音楽クリップを用い，35 名（うち 10 名は振付師またはアーティスト）の参加者に，
(1) 音楽を無視したダンスのリアルさ， 
(2) 音楽とダンスのスタイルの一致， 
(3) 音楽とダンスのリズムの一致， 
(4) 音楽とダンスの構造の一致を 0 から 10 で評価させた．
結果をFig.9に示す。我々の手法は他の手法よりも高いスコアを達成し、実際のダンスに近いものとなっている。
生成モデル（Yanら[2019]，Sunら[2020]）は，ダンス結果のほとんどが「くすんだ」「ぼやけた」印象で，
美しさに欠け，多くのアーティファクトを持つため，全体的に低いスコアを達成していることが分かる。
Leeら[2013]の結果ははるかに良いが、彼らのダンスは音楽との相関が低い。
ᵄ -testの結果（詳細は補足資料を参照）、スタイル埋め込み、リズム埋め込み、
構造的制約を用いることで大幅な改善が得られることが分かった。
また，ECを用いない手法では，アーティストと一般ユーザでそれぞれ43％以上，28％以上，
RCを用いない手法では，アーティストと一般ユーザでそれぞれ40％以上，32％以上，
SCを用いない手法では，アーティストと一般ユーザでそれぞれ34％以上，28％以上，向上することが示された．
これに対し，Ground-truthは，アーティストで6％，一般ユーザで2％以下の差しか出なかった．
また、最近、Leeら[2019]やRenら[2020]によって音楽駆動型2Dダンス生成モデルがいくつか提案されているので、
我々の3Dダンスを2Dに投影して、これらの手法との比較も行った。結果は補足動画に示す。

5.3 システム分析 
本節では，学習された振付スタイル埋め込みの全体的な性能分析を行い，我々のシステムの効率性を考察する．
振付スタイル埋め込み。
本システムの目的は、音楽とダンスのフレーズを、
類似したスタイルのセグメントが可能な限り近くに存在する統一的な潜在的空間にマッピングすることである。
ここでは、表4に分類精度を、図10に振付スタイル埋め込みのT-SNE可視化を示すことで、その性能を評価する。
個別学習後、音楽とダンスのスタイル埋め込みは既に分類可能であるが、
ペアデータの埋め込みは互いにかけ離れている。
図10（右）では、音楽とダンスの埋め込み空間がより近くなっており、
分類精度も若干低下していることから、我々のコレオミュージカルスタイル埋め込みネットワークは、
その目的を達成することができたと言えます。
DEC [Xie et al. 2016]の影響を評価するために、
式1からDEC損失を取り除いたスタイル埋め込みネットワークを追加で学習させました。
実験では、DECロスを用いて訓練したネットワークとDECロスを用いないネットワークの間で、
音楽／ダンスのスタイル分類精度に関する明らかな差は見られなかった。
しかし、潜在的なサブスタイルのクラスタは、DECロスを用いて学習したネットワークの特徴空間に明らかに
よく反映された。
図11は、このような分布の違いを音楽データで示したものである。
振付音楽リズムの埋め込み 次に、コレオミュージカルリズムの埋め込みネットワークの性能を評価した。
表5は、スタイル埋め込みの有無による分類精度の上位1位と上位3位を示したものである。
分類精度は共同学習後に向上し、スタイル埋め込みも結果に寄与しており、
𝐸𝑅𝑆の共有ネットワークの設計とスタイル埋め込みを入力として用いたことが正当化される。
また、上位1位の精度はそれほど高くないが、上位3位の精度はかなり高いことに注目する。
テストセットの音楽とダンスモーションの上位3つのリズム署名について、
基底真理に対する重み付きハミング距離の最小値を計算する。
その分布を図12に示すが、ほとんどの値が1.0未満であることがわかる。
そこで、グラフ最適化処理において、上位3つの結果を用いる。
すなわち、式6において、ᵃ = 3とする。
速度。
我々のシステムは非常に効率的であり，高品質のダンスを合成するのに数秒しか必要としない．
合成時間は，動作時間，音楽時間，エッジ数（遷移閾値ǖᵄで決まる）に対してほぼ線形である．
また、閾値ᵄを20と12の2種類に設定し、ペアダンスモーションデータ（9.91時間）と
全ダンスモーションデータ（19.91時間）を用いて速度をテストし、表6に結果を示す。
また、入力曲のスタイルとリズムの埋め込みに要する時間は0.05s以下であるため、表中では省略した。
また、構築した19.91時間分のモーショングラフのノード内・外周の分布を図示し（図13参照）、
その疎密度を示す。

5.4 システムの制御性 
制御性は、即戦力となるツールにとって極めて重要であり、
アーティストは、私たちのシステムに対して、様々な個別要求を持つかもしれません。
ここでは、ChoreoMaster がいくつかの一般的な要件にどのように適応できるかを簡単に紹介します。
補足動画で例をご紹介しています。正確なコントロール 例えば、合成結果の特定の位置に特定の
ダンスモーションを表示させたり（音楽との特定の意味的関係を持つモーション）、
合成されたダンスシーケンスの他の動きに影響を与えずに不要なモーションを置き換えたり、
移動する軌道を指定したりすることが可能です。ChoreoMasterは、データ項（すなわち、式6）に
追加のユーザー制約を追加することによって、このような制御を容易にサポートできます。
具体的には、合成されたダンスにおいて、ユーザー指定の時間間隔で、
ユーザー指定のダンスモーションノードを出現または出現しないように強制したり、
ユーザー指定の時間点におけるユーザー指定位置の近くにキャラクターのルート位置が
留まるように奨励したりすることができます。
範囲制御。ゲームや映画の世界では、ステージの外にダンサーが出ないように、
合成されるダンスの可動域を制限することもよくある要件です。
これは、コスト関数に範囲制約を追加し、指定された動作範囲に違反する動作にペナルティを与えることで
実現できる。
ノベルティ制御。Berman and James 2015]によって指摘されたように、ダンスモーショングラフは、
ダンサーや振付師の創造的プロセスを支援するために使用することもできる。
我々のシステムでは、これはエッジ遷移の閾値ǖᵄ（セクション 4.1）を下げ、
遷移の重みǖ11（式 5）を上げることで実現できる。具体的には、低いǿと高いᵄはシステムがより
オリジナルなダンスモーションを使用するよう促す傾向があり、
一方、大きいǿまたは小さいǖ11は結果においてより新しい遷移（すなわち、ダンスデータベースに
提示されていない遷移）を促す傾向がある。また，プロのアーティストからは，
ChoreoMaster が生成する斬新なトランジションからインスピレーションを得たという
ポジティブなフィードバックが多数寄せられた．
6 制限と今後の課題 
実用化に成功した ChoreoMaster だが、制限も残っている。
現在、バレエやワルツなど、データベースにないダンススタイルを合成することはできない。
これは、ダンスデータベースをさらに拡張することで対応可能である。
また、3.3 節で述べたように、我々のデータセットに含まれるすべてのダンス動作は、
アーティストが通常必要とする 4 拍の小節で構成されている。
このため、3拍子の音楽を扱う場合でも、4拍子のダンスモーションとマッチングする。
この場合も、さらにデータを収集することで、この問題を克服することができる。
最後に、本システムは、ダンス動作と歌詞の意味的な関係を扱うことができない。
また、自然言語処理モジュールなど、さらなる技術を本システムに取り入れることも興味深い。
7 おわりに 
本論文では、音楽駆動型ダンスモーション合成システム ChoreoMaster を紹介した。
本システムは、アノテーションされた高品質なデータベースを用いて、
スタイルとリズムの観点から音楽とダンスの間の接続を探索する、
新しい振付指向のコレオミュージカル埋め込みフレームワークを含んでいる。
さらに、学習された振付音楽埋め込みをグラフベースの動作合成フレームワークに組み込むことで、
様々な振付ルールを尊重した高品質なダンスモーションを頑健かつ効率的に生成するとともに、
ユーザに対して優れた制御性を提供することが可能となる。
実験により、ChoreoMaster は、プロのアーティストが認める多様で高品質なダンスモーションを、
ロバストかつ効率的に生成できることが実証された。
ChoreoMasterは、Netease Gamesのいくつかのプロジェクトにおいて、
何時間ものダンスアセットの生成に成功しており、我々の知る限り、
この目的のための業界初の制作可能なツールである。

A ネットワークアーキテクチャ 本節では、我々のネットワークアーキテクチャの詳細について説明する。表 7 と表 8 にネットワークの各レイヤの全てのテンソルサイズを示す。

図2. ChoreoMasterは、音楽とダンスのつながりを捉える音楽埋め込みモジュールと、
入力された音楽から様々な振付ルールに従った高品質のダンスモーションを生成するグラフベース動作合成
モジュールという、振付に特化した2つのモジュールから構成されている。
図3．図3: 振付スタイル埋め込みネットワークと振付リズム埋め込みネットワークからなる振付指向のネットワーク。
図4. リズムのシグネチャの例。偶数ビットは正拍、奇数ビットは半拍の存在を示す。
0が連続する場合はレガートを示す。
図5. スタイルの互換性を考慮しないと、不適切なエッジが現れ、
図のようにラブリーなモーションからセクシーやクールなモーションに変化することがある。
図6. ミラーリング、ブレンディング、リシャッフルにより、ダンスモーションが増強されている。
図7. 振付指向のダンス合成処理。本システムでは、データ項、遷移項、リピート／ミラー制約などの
振付指向の制約を用いることで、プロの美的要求を満たす高品質なダンスモーションを合成している。
色分けされた音楽セグメントは、4〜8小節の音楽フレーズを表している。
簡単のため、各音楽フレーズについて、2つの署名と1つのスタイル埋め込みのみを示す。