WEBVTT

00:00:00.433 --> 00:00:03.666
皆さん、こんにちは。私はNetEase AI Lab.のTan Zhipengです。

00:00:03.666 --> 00:00:07.666
今日はChoreoMasterについてお話します。

00:00:07.666 --> 00:00:10.666
振り付けを重視した、音楽主導型のダンスシンセ。

00:00:11.466 --> 00:00:16.833
まず始めに、私たちの仕事の動機を示すために、背景を説明します。

00:00:16.866 --> 00:00:24.733
ダンスモーションは、映画やビデオゲームにおいて一般的な要素です。
そのため、ハイクオリティな3Dダンスアニメーションの需要が高まっています。

00:00:24.733 --> 00:00:31.066
しかし、ダンスアニメーションの制作は非常にコストが高く、非効率的です。

00:00:31.066 --> 00:00:37.700
1分間のダンスアニメーションを制作するのに数千ドル、数週間を要することもあります。

00:00:37.700 --> 00:00:43.700
それに、この作業には振り付けやダンスの技術やノウハウが必要です。

00:00:43.700 --> 00:00:48.933
そのため、多くの研究者がダンスの自動合成システムを構築しようと試みています。

00:00:49.566 --> 00:00:54.500
このようなツールを構築するために、初期の研究者たちは伝統的なグラフ・ベースのモデルを使おうとしてきました。

00:00:54.500 --> 00:00:58.433
これらのモデルはロバストで安定し、制御可能です。

00:00:58.433 --> 00:01:05.766
しかし、その根本的な欠点は 
ダンスの振り付けを過小評価し，単純化してしまうことです．

00:01:05.766 --> 00:01:13.100
そして、これらのグラフベースのモデルは、実は 
音楽とダンスの間の深いクロスモーダルな関係をモデル化することができないのです。

00:01:13.766 --> 00:01:19.333
さらに、既存の方法では、広く使われている振付のルールを扱うことができません。

00:01:20.233 --> 00:01:28.900
人工知能の普及に伴い、様々な研究者により、音楽のための深層生成モデルが提案されています。
そのため，音楽に合わせてダンスモーションを合成する深層生成モデルが提案されています．

00:01:28.900 --> 00:01:35.700
これらの方法は、適切に設定された場合、振り付けと音楽の関係をよりよくモデル化することができるようです。

00:01:35.700 --> 00:01:40.766
しかし、その最も明らかな欠点は、制御性が低いことです。

00:01:40.766 --> 00:01:48.766
さらに、高周波の動きはノイズとみなされ、意図的に無視される可能性があります。
ノイズとみなされ、学習過程で意図的に無視されることがあります。

00:01:48.766 --> 00:01:52.766
その結果、いくつかの結果は「鈍い」「ぼやけた」ものになります。

00:01:52.766 --> 00:01:58.733
さらに、既存の手法は一般的に振付のルールに対する明示的な配慮を欠いています。

00:01:58.733 --> 00:02:09.000
そのため、このモデルの一般化には限界があり
そのため、モデルの一般化には限界があり、トレーニングセット以外の音楽を与えると、奇妙で美しくない動きを生成してしまう可能性があります。

00:02:09.533 --> 00:02:15.300
では、どのようなものが制作に適した音楽駆動型ダンス合成ツールになるのでしょうか？

00:02:15.300 --> 00:02:20.366
まず第一に、ユーザーが合成プロセスを完全にコントロールできることです。

00:02:20.600 --> 00:02:25.400
第二に，高品質なダンスモーションを頑強かつ安定的に生成することです。

00:02:25.400 --> 00:02:31.000
ここでいう高品質とは，コログラフィーの法則を満たすものであることを意味します。

00:02:31.033 --> 00:02:34.900
このシステムによって生成された2つの踊りを見てみましょう。

00:02:35.666 --> 00:02:39.300
振り付けルールを適用しない場合の結果を見ると 

00:02:39.300 --> 00:02:43.200
というように、ダンスの動きが滑らかにつなぎ合わされたようにしか見えません。

00:02:43.200 --> 00:02:47.133
全体的にうまく構成された芸術作品には見えません。

00:02:47.133 --> 00:02:50.600
では、基本的な振付のルールとは何でしょうか？

00:02:50.600 --> 00:02:59.400
幸いなことに、プロのアーティストに相談したり、振付音楽学を研究したりした結果、いくつかの広く使われているルールが見つかりました。

00:02:59.400 --> 00:03:06.666
第一は、スタイルの一貫性です。
音楽と体の動きは同じような雰囲気と音色を伝える必要があります。

00:03:06.666 --> 00:03:13.966
第二に、リズムの一貫性です。
各シンクロダンスと音楽のセグメントは同じリズムパターンを提示する必要があります。

00:03:14.633 --> 00:03:17.833
3つ目は構造の一貫性です。

00:03:17.833 --> 00:03:22.433
踊りの構成は音楽と協調していなければなりません。

00:03:22.433 --> 00:03:27.433
例えば、繰り返される音楽のフレーズは、繰り返される動作に割り当てられるのが普通です。

00:03:28.100 --> 00:03:36.033
このようなルールに基づいて、私たちはChoreoMaster, 
を開発しました．

00:03:36.033 --> 00:03:42.000
私たちは、コレオミュージックの埋め込みモジュールを設計しました。
このモジュールはスタイルとリズムの埋め込みを学習します。

00:03:42.000 --> 00:03:51.866
学習された埋め込みは、グラフベースのフレームワークに組み込まれます。
グラフベースのフレームワークに組み込まれ、高品質なダンスモーションを制御可能にする。

00:03:51.866 --> 00:03:55.900
次に、我々のシステムの技術的な詳細を紹介します。

00:03:56.633 --> 00:04:01.100
まず始めに、スタイルとリズムの関係について説明します。


00:04:04.533 --> 00:04:08.100
この2つのダンスは、実は同じリズムパターンを共有していることがわかります。

00:04:08.100 --> 00:04:11.066
しかし、視覚的なスタイルは全く異なっています。

00:04:11.066 --> 00:04:14.933
つまり、スタイルとリズムは比較的独立していると言えるでしょう。

00:04:14.966 --> 00:04:16.966
ここでもう一つ例を挙げます。

00:04:17.000 --> 00:04:22.866
このような癒し系の音楽は、先ほどの音楽よりもずっと柔らかいリズムになる傾向があることがわかります。

00:04:23.766 --> 00:04:27.500
つまり、スタイルとリズムはやはりある程度の相関関係があるということですね。

00:04:27.500 --> 00:04:33.033
リズムパターンの分布は音楽とダンスのスタイルに強く関連しています。

00:04:34.133 --> 00:04:40.866
このような複雑なスタイルとリズムの関係を管理するために 
コレオミュージカルエンベッディングネットワークを設計しました。

00:04:42.066 --> 00:04:49.066
一方、スタイルとリズムは比較的独立しているので、スタイルとリズムを分離しました。
スタイルとリズムの埋め込みネットワークを分離してみました。

00:04:49.066 --> 00:04:55.066
choreomusical style embedding networkとchoreomusical rhythm embedding networkを構築します。

00:04:55.066 --> 00:04:59.433
そうすることで、システムの解釈可能性や制御性も向上すると思います。

00:04:59.433 --> 00:05:06.033
一方、リズムパターンの分布は音楽やダンスのスタイルと関係があるので。

00:05:06.066 --> 00:05:10.266
というように、リズム埋め込みネットワークにスタイル埋め込みを連結しています。

00:05:10.633 --> 00:05:15.666
スタイル埋め込みの話をする前に、重要な疑問があります。

00:05:15.666 --> 00:05:21.933
なぜ、音楽とダンスを手作業で分けるという素直な解決策をとらないのか？
音楽とダンスをいくつかのスタイル・カテゴリーに分類することです

00:05:21.933 --> 00:05:28.700
この画像から、異なる音楽やダンスのスタイルの境界線は 
必ずしも明確ではないことが分かります。

00:05:28.733 --> 00:05:34.500
さらに、音楽とダンスのスタイルの分類基準も異なっています。

00:05:34.533 --> 00:05:39.500
ほとんどの音楽やダンスのジャンルには、相手方に相当するタグがありません。

00:05:39.533 --> 00:05:44.366
また、音楽やダンスの主なスタイルには、数多くのサブスタイルが存在します。

00:05:44.366 --> 00:05:50.500
例えば、ヒップホップはさらにポッピング、ロック、ブレイキング、アーバンなどに分類される。

00:05:50.533 --> 00:05:59.833
そこで、我々はコレオミュージカルスタイルの埋め込みネットワーク 
を採用し、音楽とダンスのセグメントを暗黙のうちに統一的な埋め込み空間にマッピングしています。

00:05:59.833 --> 00:06:03.933
ここで、似たような雰囲気やトーンを伝えるセグメントは密接にクラスタ化されます。

00:06:03.933 --> 00:06:07.366
そのアーキテクチャは図に示すとおりです。

00:06:07.400 --> 00:06:14.066
音楽符号化ブランチEmについては 
バックボーンとして最先端の音楽タグ付けネットワークを採用しています。

00:06:14.100 --> 00:06:18.866
4つの畳み込みブロック層と2つのGRU層で構成されています。

00:06:18.900 --> 00:06:26.166
グラフ畳み込みブロックを使った以外は、対称的なダンスエンコードブランチEdを構築しています。

00:06:26.200 --> 00:06:33.400
音楽とダンスのフレーズは32次元の埋め込みベクトル(ZmとZd)に圧縮されます

00:06:33.400 --> 00:06:41.166
膨大な量の音楽と動きのペアリングされていないデータを利用するため、2段階の学習方法を採用した。
2段階の学習方法を採用しました。

00:06:41.433 --> 00:06:48.833
1つ目は分離学習ステージで、両ブランチはペアリングされていないデータを用いて独立して学習されます。

00:06:48.866 --> 00:06:55.166
潜在的なサブスタイルをよりよく反映させるために、教師なしDEC戦略を取り入れる。

00:06:55.166 --> 00:07:00.133
つまり、損失関数は分類損失とDEC損失の和になります。

00:07:00.133 --> 00:07:07.766
2つ目は共同学習フェーズで、音楽と動きのペアを用いて2つのブランチを共同学習させます。

00:07:07.766 --> 00:07:12.766
そして、音楽とモーションの埋め込み間のMSEロスを損失関数に追加します。

00:07:12.800 --> 00:07:18.266
こちらは共同学習前後のスタイル埋め込みをT-SNEで可視化したものです。

00:07:18.300 --> 00:07:23.033
のように、MusicとDanceのペアが、より近い埋め込みになっていることがわかります。

00:07:24.400 --> 00:07:27.666
こちらは、スタイルの埋め込みに関するアブレーション研究です。

00:07:46.033 --> 00:07:52.066
リズムはスタイルと異なり、音楽の拍子記号や譜割りを使って明確に表現することができます

00:07:52.100 --> 00:07:59.366
例えば、この画像では4/4拍子ですが、これは1つの拍子に4つのビートが存在することを示しています。

00:07:59.366 --> 00:08:04.700
しかし、ダンスの動きと音楽のリズムを合わせることは、まだまだ難しい課題です。

00:08:04.700 --> 00:08:13.533
音楽は通常、複数の楽器とボーカルで構成されています。
ダンスは多くの関節が同時に動きます。

00:08:13.566 --> 00:08:21.433
そのリズムの関係をよりよく理解するために、プロのアーティストにビートパターンを指定してもらいました。

00:08:21.433 --> 00:08:28.300
この結果を解析すると、実はビートパターンは8ビットの2進数ベクトルで表現できることがわかりました。

00:08:28.300 --> 00:08:31.200
これはリズム記号と呼ばれるものです。

00:08:31.200 --> 00:08:35.800
偶数ビットが正規の主拍を表します。

00:08:35.800 --> 00:08:38.500
奇数ビットが2分音符を表します。

00:08:38.500 --> 00:08:45.033
ゼロの連続はレガート、つまり音楽やダンスの動作における滑らかな周期を表します。

00:08:45.033 --> 00:08:49.400
また、一般的なリズム記号は13種類しかありません。

00:08:49.400 --> 00:08:53.333
となり、それらの間の距離はハミング距離で定義できます。

00:08:53.333 --> 00:08:56.533
ここで、リズム記号の例をいくつか示します。

00:09:13.033 --> 00:09:19.033
リズム記号を分類するために、Choreomusical Rhythm embedding networkを設計しました。

00:09:19.066 --> 00:09:27.733
図に示すように、音楽とダンスの特徴抽出から構成される。
そしてリズム記号を分類するための共有ブロックです。

00:09:27.733 --> 00:09:30.066
スタイル埋め込みは入力として連結される

00:09:30.066 --> 00:09:39.300
また、低レベルの原信号からネットワークを学習させる必要はないため、抽出した音楽をネットワークに与えています。
抽出された音楽と動きの特徴をネットワークに与えます。

00:09:39.866 --> 00:09:46.000
このネットワークのすべてのブロックは、ラベル付けされたペア音楽とダンスデータを使って共同で学習されます。

00:09:46.000 --> 00:09:53.166
損失関数のLdrとLmrは、それぞれダンスと音楽の分類損失を表しています。

00:09:53.700 --> 00:09:56.933
こちらはリズムの埋め込みに関するアブレーション研究です。

00:10:13.333 --> 00:10:18.200
最後に，振り付けを考慮したグラフベースのフレームワークを紹介します．

00:10:18.400 --> 00:10:20.800
モーショングラフとは、有向グラフのことです。

00:10:20.800 --> 00:10:26.766
ここで、各ノードは運動セグメントを表し、各エッジは遷移コストを表す。

00:10:27.300 --> 00:10:31.766
従来のグラフ構築と比較すると、主に以下のような違いがある。

00:10:31.766 --> 00:10:37.033
第一の違いは、グラフ構築の際に局所的な構造制約を導入している点です。

00:10:37.033 --> 00:10:41.433
ダンスモーションビートではなく、ダンスモーションメーターをモーションノードとして使用しています。

00:10:41.433 --> 00:10:46.833
2つ目は、遷移コストを計算する際に、Style embeddingを考慮することです。

00:10:46.833 --> 00:10:53.033
これによって、右のようなスタイルに互換性のないトランジション例を回避することができるかもしれません。

00:10:53.033 --> 00:10:58.466
さらに、ミラーリングやブレンディング、シャッフルなど、ダンスモーションはさらに拡張されます。

00:10:58.466 --> 00:11:00.100
右はその例です。

00:11:00.100 --> 00:11:04.100
2.56の増大率を達成しました。

00:11:04.633 --> 00:11:09.900
モーショングラフを作成することで、音楽に合わせて新しいダンスを最適化することができます。

00:11:09.900 --> 00:11:16.733
音楽が入力されると、まず音楽のセグメンテーションと類似性ラベリング手法を適用します。

00:11:16.733 --> 00:11:20.200
そして、類似したミュージックメーターには同じIDが与えられます。

00:11:20.200 --> 00:11:24.466
そして、この関数を最適化する最適経路をモーショングラフで探します。

00:11:24.666 --> 00:11:26.833
この関数は3つの部分を含んでいます。

00:11:26.833 --> 00:11:31.933
データ項では、音楽と動作のスタイルやリズムのマッチングに必要なコストを計算します。

00:11:31.933 --> 00:11:36.533
Transition項は、隣接するモーションセグメント間のスムーズな遷移を保証します。

00:11:37.133 --> 00:11:41.266
構造項は、音楽とダンスの構造的な一貫性を扱います。

00:11:41.933 --> 00:11:46.866
そして、振付のルールから反復制約とミラー制約を含んでいます。

00:11:48.033 --> 00:11:52.466
この関数は動的計画法アルゴリズムを用いて最適化することができます。

00:11:53.066 --> 00:11:55.800
以下は構造制約のあるアブレーション研究です。

00:12:19.266 --> 00:12:22.200
次に、我々の手法の評価を示します。

00:12:23.266 --> 00:12:30.600
このデータベースには19.91時間のダンスモーションが含まれており、そのうち9.91時間にはペアとなる音楽が含まれています。

00:12:31.166 --> 00:12:35.600
さらに、102.5時間の音楽データセットも収集しました。

00:12:36.433 --> 00:12:40.833
ダンスと音楽は、2次元のスタイルとリズム記号でラベル付けされます。

00:12:41.466 --> 00:12:46.533
このシステムは14時間の学習が必要でしたが、数秒でダンスを合成することができました。

00:12:47.766 --> 00:12:51.600
ChoreoMasterが自動的に生成した結果を示します。

00:14:37.366 --> 00:14:40.566
また、1つの音楽に対する多様な生成にも対応しています。

00:14:40.566 --> 00:14:44.766
最適化を数回行い、使用したモーションをスキップすることで対応可能です。

00:14:57.666 --> 00:15:01.833
私たちはこの方法をいくつかの他のダンス生成方法と比較しました。

00:15:55.366 --> 00:16:00.133
また、我々の方法を定性的に評価するために、ユーザー調査を行いました。

00:16:00.700 --> 00:16:07.400
30曲のテスト音源を使用し、35名の参加者（うち10名は振付家・アーティスト）を募りました。

00:16:08.000 --> 00:16:13.600
その結果、ダンスのリアルさ、スタイル、リズム、構造の一貫性などを評価してもらいます。

00:16:14.366 --> 00:16:19.000
この表から、私たちの方法が他の方法よりも高い得点を獲得していることが分かります。

00:16:19.000 --> 00:16:22.100
となり，実際のダンスに近くなっています．

00:16:23.300 --> 00:16:28.600
これまで述べてきたように、制御性は生産可能なツールにとって極めて重要です。

00:16:29.100 --> 00:16:33.766
ここでは、ChoreoMasterがどのように一般的な要件に適応できるかを紹介します。

00:16:34.433 --> 00:16:39.666
アーティストにとって最も一般的な要求は、合成された結果を正確にコントロールすることです。

00:16:40.400 --> 00:16:45.600 例えば、ある特定のダンス動作を特定の場所に出現させるなどです。

00:16:46.466 --> 00:16:50.700
他の動きに影響を与えずに不要な動きを置き換える、などです。

00:16:51.566 --> 00:16:57.400
そのほか、キャラクターの根元の位置を促すことで軌跡の制御をサポートしています 

00:16:57.400 --> 00:17:02.466
のように、指定した時間帯に指定した場所に近づくような軌道制御も可能です。

00:17:04.766 --> 00:17:11.833
また、ダンサーが舞台からはみ出さないように可動域を制限することもよくある要件です。

00:17:11.833 --> 00:17:20.433
これは、コスト関数に範囲制約を追加することで実現できる。
指定された範囲に違反する動作にペナルティを与えることで、実現できます。

00:17:21.166 --> 00:17:26.700
さらに、ダンスモーショングラフは、創造的なプロセスを支援するために使用することもできます。

00:17:27.133 --> 00:17:32.600
本システムでは、エッジ遷移の閾値Tを下げることでこれを実現することができる。

00:17:32.600 --> 00:17:37.566
とし、遷移の重みλ11を大きくすることで、より新しい遷移を促すことができます。

00:17:48.700 --> 00:17:53.633
実用化に成功したChoreoMasterですが、まだまだ限界は残されています。

00:17:53.833 --> 00:18:02.633
現状では、データベースにないダンススタイルを合成することはできません。
これはダンスデータベースをさらに拡張することで対応可能です。

00:18:03.500 --> 00:18:09.866
さらに、現在は4拍子の音楽しかサポートしていません。
これもまた、さらなるデータ取得によってこの問題を克服することができます。

00:18:11.133 --> 00:18:17.233
最後に、我々のシステムはダンスの動作と音楽の歌詞の間の意味的な関係をまだ扱うことができません。

00:18:17.766 --> 00:18:22.800
NLPモジュールなど、さらなる技術をシステムに取り入れると面白いかもしれませんね。

00:18:23.800 --> 00:18:32.500
最後に、建設的なコメントをいただいた査読者の方々に感謝します。
そして、我々のシステムを改善するために時間と素晴らしい専門知識を提供してくれたアーティストに感謝します。

00:18:32.966 --> 00:18:36.866
ユーザー調査の参加者の方々には、お時間と忍耐をいただき、感謝いたします。

00:18:36.866 --> 00:18:40.866
この研究は、国家重点技術RDプログラムの支援を受けて行われました。

00:18:44.266 --> 00:18:44.266 
中国国家自然科学基金会

00:18:44.266 --> 00:18:48.100
北京市高等機関工程研究センター研究助成金。

00:18:48.666 --> 00:18:49.966
ご清聴ありがとうございました。